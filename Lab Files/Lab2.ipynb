{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF0krky2N4dr"
   },
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to use the software stack of MASE. There are in total 7 tasks you would need to finish, and 1 optional task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIOZ48aaMqhV"
   },
   "source": [
    "# Turning you network to a graph\n",
    "\n",
    "One specific feature of MASE is its capability to transform DL models to a computation graph using the [torch.fx](<https://pytorch.org/docs/stable/fx.html>) framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjBbOikbLJdN"
   },
   "source": [
    "## Use the Transform functionality without CLI\n",
    "\n",
    "This tutorial describes how to use the MASE transform functionality for a pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5sg0OpYLJdO"
   },
   "source": [
    "## Import related packages and machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laurie2905/mase/machop\n"
     ]
    }
   ],
   "source": [
    "cd ../machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "# set_logging_verbosity(\"info\")\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q35_tV4QLJdQ"
   },
   "source": [
    "## Set up the dataset\n",
    "\n",
    "Here we create a `MaseDataModule` using the `jsc` dataset from lab1. Note the `MaseDataModule` also requires the name of the model you plan to use data module with. In this case it is `jsc-tiny`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ztEzclWrLJdR"
   },
   "outputs": [],
   "source": [
    "# Why do we set batchsize to 8 here\n",
    "batch_size = 8\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/laurie2905/mase/machop'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08-4XdNYLJdR"
   },
   "source": [
    "## Set up the model \n",
    "\n",
    "Here we use the previously trained `jsc-tiny` model in lab 1 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gIU4s9CiLJdR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../mase_output/batch_128/jsc-tiny_classification_jsc_2024-01-25/software/training_ckpts/best.ckpt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Change directory (if necessary)\n",
    "# %cd ../mase_output/batch_32/jsc-tiny_classification_jsc_2024-01-25/software/training_ckpts\n",
    "\n",
    "# Assuming get_model_info and get_model functions are defined and data_module is available\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "model = load_model(load_name=\"../mase_output/batch_128/jsc-tiny_classification_jsc_2024-01-25/software/training_ckpts/best.ckpt\", load_type=\"pl\", model=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrIWs8XvLJdR"
   },
   "source": [
    "# Get a dummy data in\n",
    "With the dataset module and model information, we can grab an input generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ygyzBWJyLJdR"
   },
   "outputs": [],
   "source": [
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sucUgAVLJdS"
   },
   "source": [
    "## Generate a MaseGraph\n",
    "We have two forms of passes: transform passes and analysis passes, both of them would require the model to be transferred into a MaseGraph to allow manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wSmp6oaGLJdS"
   },
   "outputs": [],
   "source": [
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiEehxhNLJdS"
   },
   "source": [
    "## Running an Analysis pass\n",
    "Analysis pass DOES NOT change the graph\n",
    "\n",
    "The following analysis passes are essential to prepare the graph for other passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UuXo32cJLJdS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    return seq_blocks_3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAE-LFypLJdS"
   },
   "source": [
    "We will first run a simple graph analysis to understand the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V4c2sgqdLJdS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    return seq_blocks_3\n",
      "Network overview:\n",
      "{'placeholder': 1, 'get_attr': 0, 'call_function': 0, 'call_method': 0, 'call_module': 4, 'output': 1}\n",
      "Layer types:\n",
      "[BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Linear(in_features=16, out_features=5, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "# report graph is an analysis pass that shows you the detailed information in the graph\n",
    "from chop.passes.graph import report_graph_analysis_pass\n",
    "_ = report_graph_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjIq-hnWLJdS"
   },
   "source": [
    "## Running another Analysis pass: Profile statistics\n",
    "\n",
    "The pass `profile_statistics_analysis_pass` collects statistics of parameters and activations, and save them to node's metadata.\n",
    "\n",
    "Here is a list of all the supported statistics. Refer to the `__init__` of statistic classes in `chop.passes.analysis.statistical_profiler.stat` to check the args each stat class takes.\n",
    "\n",
    "This is a more complex analysis than the previous pass, and thus it would require you to pass in additional arguments for this pass.\n",
    "\n",
    "### Example: the range of weights & input activations of nodes\n",
    "\n",
    "Say we want to collect the tensor-wise min-max range of the 1st `torch.nn.Linear` nodes' weights & bias, and the channel-wise 97% quantile min-max of the 1st `torch.nn.Linear` nodes' input activations. We can do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Val of Weights and Biases: This part refers to analyzing the first linear layer (torch.nn.Linear) in the model and collecting the minimum and maximum values of its weights and biases. \"Tensor-wise\" here means that you are looking at the entire tensor of weights and biases as a whole. For each tensor (one for weights and one for biases), you identify the minimum and maximum values. This type of analysis is useful for understanding the range of values your weights and biases are taking, which can be important for tasks like model quantization or normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the channel-wise 97% quantile min-max of the 1st torch.nn.Linear nodes' input activations: Analyzing the inputs to the first linear layer of the model. \"Channel-wise\" means the analysis is done separately for each channel (or feature) of the input tensor. In the context of a torch.nn.Linear layer, each 'channel' can be thought of as a feature in the input vector. \"97% quantile min-max\" refers to finding the range within which 97% of the data lies for each channel. In other words, for each channel, you identify the values between which 97% of the activation values fall. This is done to capture the typical range of activation values, excluding extreme outliers. Valuable for understanding the distribution of activation values, which can be critical for optimizing and scaling neural networks, especially for tasks like robust quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wTcTTDV8LJdS"
   },
   "outputs": [],
   "source": [
    "\n",
    "pass_args = {\n",
    "    \"by\": \"type\",                                                            # collect statistics by node name\n",
    "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
    "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
    "    \"weight_statistics\": {\n",
    "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
    "    },\n",
    "    \"activation_statistics\": {\n",
    "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
    "    },\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhxtJNCVLJdT"
   },
   "source": [
    "We can use the `report_node_meta_param_analysis_pass` to inspect the collected statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OGAXEK29LJdT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling weight statistics: 100%|██████████| 6/6 [00:00<00:00, 710.56it/s]\n",
      "Profiling act statistics: 100%|██████████| 4/4 [00:00<00:00, 126.84it/s]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| Node name    | Fx Node op   | Mase type           | Mase op      | Software Param                                                                         |\n",
      "+==============+==============+=====================+==============+========================================================================================+\n",
      "| x            | placeholder  | placeholder         | placeholder  | {'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                        |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                 |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 512,                      |\n",
      "|              |              |                     |              |                                                     'max': 4.539982795715332,          |\n",
      "|              |              |                     |              |                                                     'min': -2.518634796142578,         |\n",
      "|              |              |                     |              |                                                     'range': 7.05861759185791}}}},     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 5,                           |\n",
      "|              |              |                     |              |                                                  'mean': 0.4399837553501129,           |\n",
      "|              |              |                     |              |                                                  'variance': 0.5954206585884094}}},    |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 80,                        |\n",
      "|              |              |                     |              |                                                    'mean': -0.06088832765817642,       |\n",
      "|              |              |                     |              |                                                    'variance': 0.7507548928260803}}}}, |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_3 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 160,                      |\n",
      "|              |              |                     |              |                                                     'max': 4.638716697692871,          |\n",
      "|              |              |                     |              |                                                     'min': -32.42861557006836,         |\n",
      "|              |              |                     |              |                                                     'range': 37.06733322143555}}}},    |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| output       | output       | output              | output       | {'args': {'data_in_0': {'stat': {}}}}                                                  |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6330lcJfLJdT"
   },
   "source": [
    "## Running a Transform pass: Quantisation\n",
    "\n",
    "As its name suggests, the transform pass would modify the `MaseGraph`.\n",
    "Similar to the previous analysis pass example, we would need to first declare the configuration for the pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization, in the context of machine learning and neural networks, is a technique used to reduce the precision of the numbers used in a model's calculations. It's like using a simpler, rougher scale to measure something instead of a highly precise one. Quantization typically involves converting floating-point numbers (which can represent a very wide range of values with high precision) into integers (which represent a more limited range of values with less precision). For instance, a model might originally use 32-bit floating-point numbers, but with quantization, it could be using 8-bit integers. \n",
    "\n",
    "1. Reduced Model Size: Using lower precision numbers means each number takes up less memory, so the entire model is smaller.\n",
    "\n",
    "2. Faster Performance: Calculations with integers are generally faster than with floating-point numbers, especially on certain hardware.\n",
    "\n",
    "3. Lower Power Consumption: This is especially important for running models on mobile devices or other hardware with limited power resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "t3MO3JYQLJdT"
   },
   "outputs": [],
   "source": [
    "pass_args = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLuqdnuLLJdT"
   },
   "source": [
    "We can then proceed to apply the transformation, in this case, we kept the original graph on purpose, so that we can print a `diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zPiJQvs4LJdT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    return seq_blocks_3\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mCompare nodes:\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34m\n",
      "| Ori name     | New name     | MASE_TYPE           | Mase_OP      | Original type   | Quantized type   | Changed   |\n",
      "|--------------+--------------+---------------------+--------------+-----------------+------------------+-----------|\n",
      "| x            | x            | placeholder         | placeholder  | x               | x                | False     |\n",
      "| seq_blocks_0 | seq_blocks_0 | module              | batch_norm1d | BatchNorm1d     | BatchNorm1d      | False     |\n",
      "| seq_blocks_1 | seq_blocks_1 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| seq_blocks_2 | seq_blocks_2 | module_related_func | linear       | Linear          | LinearInteger    | True      |\n",
      "| seq_blocks_3 | seq_blocks_3 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| output       | output       | output              | output       | output          | output           | False     |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       1 |         0 |           1 |\n",
      "| Linear          | linear       |       1 |         1 |           0 |\n",
      "| ReLU            | relu         |       2 |         0 |           2 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "ori_mg = MaseGraph(model=model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "\n",
    "mg, _ = quantize_transform_pass(mg, pass_args)\n",
    "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhTU3755MerQ"
   },
   "source": [
    "\n",
    "\n",
    "# Exercises:\n",
    "\n",
    "We have now seen how to:\n",
    "1. Set up a dataset\n",
    "2. Set up a model\n",
    "3. Generate a `MaseGraph` from the model\n",
    "4. Run Analysis and Transform passes on the `MaseGraph`\n",
    "\n",
    "Now consider the following problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the functionality of `report_graph_analysis_pass` and its printed jargons such as `placeholder`, `get_attr` ... You might find the doc of [torch.fx](https://pytorch.org/docs/stable/fx.html) useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used to produce a report for the graph analysis of a MaseGraph. It takes a MaseGraph as an input and counts the different node operations and module types then returns a tuple of a MaseGraph and an empty dictionary of types of operations. \n",
    "\n",
    "The operations are defined as follows:\n",
    "\n",
    "1. placeholder: Represents inputs to the model; 'name' assigns input names, 'target' names the argument, 'args' nothing or default parameter of function input, 'kwargs' unused.\n",
    "\n",
    "2. get_attr: These nodes are used to fetch parameters from your model, such as weights from layers. They locate the parameters within the model’s structure. Fetches a parameter from the module hierarchy; 'name' labels the result, 'target' identifies the parameter's location in the hierarchy, 'args' and 'kwargs' are unused.\n",
    "\n",
    "3. call_function: These nodes represent the application of standalone functions (like torch.add) on data. They keep track of the function being used and the arguments it takes.Applies a function to values; 'name' labels the result, 'target' is the function, 'args' and 'kwargs' are the function's arguments, following Python's convention\n",
    "\n",
    "4. call_module: These are used when a specific module (a layer in your neural network) is called. 'name' labels the result, 'target' is the module's location in the hierarchy, 'args' and 'kwargs' are arguments excluding 'self'.\n",
    "\n",
    "5. call_method: Similar to Call_Function, but these nodes are for methods that belong to an object (like tensor.view()). They record the method being called, including the object it is called on (self) and other arguments. 'name' for labeling, 'target' is the method's name, 'args' and 'kwargs' include all method arguments including 'self'.\n",
    "\n",
    "6. output: Correspond to the return values of functions or the final output of your model.\n",
    "\n",
    "The function appends a network overview and layer types information to the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    return seq_blocks_3\n",
      "Network overview:\n",
      "{'placeholder': 1, 'get_attr': 0, 'call_function': 0, 'call_method': 0, 'call_module': 4, 'output': 1}\n",
      "Layer types:\n",
      "[BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), LinearInteger(in_features=16, out_features=5, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# report graph is an analysis pass that shows you the detailed information in the graph\n",
    "from chop.passes.graph import report_graph_analysis_pass\n",
    "_ = report_graph_analysis_pass(mg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What are the functionalities of `profile_statistics_analysis_pass` and `report_node_meta_param_analysis_pass` respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile_statistics_analysis_pass\n",
    "Function performs a series of operations on a given graph section to collect profile and computes statistics (See Below) related to the weights and activations of the nodes metadata.\n",
    "\n",
    "#### Args\n",
    "Graph Node Identification by Name: Targets nodes in the graph whose names match entries in target_weight_nodes or target_act_nodes for statistical analysis.\n",
    "\n",
    "Targeting by Type or Attribute: Uses a common characteristic, defined by mase_op, to identify nodes for analysis; applicable for various operation types like convolution, pooling, etc.\n",
    "\n",
    "target_weight_nodes: Specifies which weight layers' data should be recorded for statistical analysis.\n",
    "\n",
    "target_act_nodes: Designates activation nodes to record statistics for.\n",
    "\n",
    "weight_stats: Determines the type of statistics to be collected for weight nodes.\n",
    "\n",
    "act_stats: Defines dimensions, quantile, and device for activation statistics collection.\n",
    "\n",
    "#### Statistics\n",
    "Record: Keeps a record of all samples passed to it. It allows for samples to be moved to a specific device and adds a new dimension before concatenation if required.\n",
    "\n",
    "VarianceOnline: Calculates the running variance and mean using Welford's online algorithm, which is more memory-efficient as it does not require storing all samples.\n",
    "\n",
    "VariancePrecise: Computes the variance and mean by concatenating samples and using torch.var and torch.mean. It is more precise but uses more memory, which can be significant for large datasets.\n",
    "\n",
    "RangeNSigma: Determines the range of samples within n standard deviations (sigma) from the mean. It assumes a normal distribution and can operate in either 'precise' or 'online' mode for variance calculation.\n",
    "\n",
    "RangeMinMax: Calculates the range of samples based on the minimum and maximum values. It can also take the absolute value of samples before calculation.\n",
    "\n",
    "RangeQuantile: Computes the range based on quantiles. It can take the absolute values of samples and reduce along specified dimensions.\n",
    "\n",
    "AbsMean: Implements an online algorithm to compute the mean of the absolute values of the samples.\n",
    "\n",
    "### report_node_meta_param_analysis_pass\n",
    "\n",
    "Report Generation: Constructs a table with headers based on selected parameter categories:\n",
    "\n",
    "Includes basic information like node name, operation type (Fx Node op), and Mase type and Mase op.\n",
    "\n",
    "\"which\": Specifies which categories of parameters to include in the report (options: \"all\", \"common\", \"hardware\", \"software\").\n",
    "\n",
    "\"save_path\": Defines a file path where the analysis report will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASE OPs and MASE Types\n",
    "\n",
    "MASE is designed to be a very high-level intermediate representation (IR), this is very different from the classic [LLVM IR](https://llvm.org/docs/LangRef.html) that you might be familiar with.\n",
    "\n",
    "The following MASE Types are available:\n",
    "(Note from Aaron: do we have a page somewhere that have summarized this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A deeper dive into the quantisation transform\n",
    "\n",
    "3. Explain why only 1 OP is changed after the `quantize_transform_pass` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    return seq_blocks_3\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mCompare nodes:\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34m\n",
      "| Ori name     | New name     | MASE_TYPE           | Mase_OP      | Original type   | Quantized type   | Changed   |\n",
      "|--------------+--------------+---------------------+--------------+-----------------+------------------+-----------|\n",
      "| x            | x            | placeholder         | placeholder  | x               | x                | False     |\n",
      "| seq_blocks_0 | seq_blocks_0 | module              | batch_norm1d | BatchNorm1d     | BatchNorm1d      | False     |\n",
      "| seq_blocks_1 | seq_blocks_1 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| seq_blocks_2 | seq_blocks_2 | module_related_func | linear       | Linear          | LinearInteger    | True      |\n",
      "| seq_blocks_3 | seq_blocks_3 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| output       | output       | output              | output       | output          | output           | False     |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       1 |         0 |           1 |\n",
      "| Linear          | linear       |       1 |         1 |           0 |\n",
      "| ReLU            | relu         |       2 |         0 |           2 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pass_args = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    \n",
    "    },\n",
    "}\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "ori_mg = MaseGraph(model=model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "\n",
    "mg, _ = quantize_transform_pass(mg, pass_args)\n",
    "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As only one call_module type (Linear) is being specified to be quantised in the transform pass. Furthermore, in the jsc-tiny model there is one linear operator. If relu was chosen to be quantised then there would be 2 changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write some code to traverse both `mg` and `ori_mg`, check and comment on the nodes in these two graphs. You might find the source code for the implementation of `summarize_quantization_analysis_pass` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference found at name: seq_blocks_2, MASE type: module_related_func, MASE operation: linear\n",
      "Original module: <class 'torch.nn.modules.linear.Linear'> --> New module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.linear.LinearInteger'>\n"
     ]
    }
   ],
   "source": [
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "from chop.passes.graph.utils import get_mase_op, get_mase_type, get_node_actual_target\n",
    "import torch\n",
    "\n",
    "# Iterate over pairs of nodes from the original and modified graphs\n",
    "for ori_n, n in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
    "    # Check if the node's target module has changed type after modification\n",
    "    if type(get_node_actual_target(n)) != type(get_node_actual_target(ori_n)):\n",
    "        \n",
    "        # Retrieve the original and quantized modules from the nodes\n",
    "        ori_module = get_node_actual_target(ori_n)\n",
    "        quant_module = get_node_actual_target(n)\n",
    "        \n",
    "        # Print the difference information\n",
    "        print(f'Difference found at name: {n.name}, '\n",
    "              f'MASE type: {get_mase_type(n)}, MASE operation: {get_mase_op(n)}\\n'\n",
    "              f'Original module: {type(ori_module)} --> '\n",
    "              f'New module: {type(quant_module)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mg_node, ori_mg_node in zip(mg.fx_graph.nodes, ori_mg.fx_graph.nodes):\n",
    "#     print(mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"])\n",
    "#     if mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"] == \"linear\" and ori_mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"] == \"linear\":\n",
    "#         # # mg_weight = mg_node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"]\n",
    "#         # # ori_mg_weight = ori_mg_node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"]\n",
    "#         print(f\"mg Node: {mg_node.name}, Weight: {mg_weight} \\n ori_mg Node: {ori_mg_node.name}, Weight: {ori_mg_weight}\")\n",
    "        \n",
    "#         # print(f\"mg Node: {mg_node.name}, Weight: {mg_weight} \\n ori_mg Node: {ori_mg_node.name}, Weight: {ori_mg_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling weight statistics: 100%|██████████| 6/6 [00:00<00:00, 8385.81it/s]\n",
      "Profiling act statistics: 100%|██████████| 4/4 [00:00<00:00, 112.55it/s]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| Node name    | Fx Node op   | Mase type           | Mase op      | Software Param                                                                         |\n",
      "+==============+==============+=====================+==============+========================================================================================+\n",
      "| x            | placeholder  | placeholder         | placeholder  | {'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                        |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                 |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 512,                      |\n",
      "|              |              |                     |              |                                                     'max': 5.146173000335693,          |\n",
      "|              |              |                     |              |                                                     'min': -2.6190335750579834,        |\n",
      "|              |              |                     |              |                                                     'range': 7.765206336975098}}}},    |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 5,                           |\n",
      "|              |              |                     |              |                                                  'mean': 0.4399837553501129,           |\n",
      "|              |              |                     |              |                                                  'variance': 0.5954206585884094}}},    |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 80,                        |\n",
      "|              |              |                     |              |                                                    'mean': -0.06088832765817642,       |\n",
      "|              |              |                     |              |                                                    'variance': 0.7507548928260803}}}}, |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| seq_blocks_3 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 160,                      |\n",
      "|              |              |                     |              |                                                     'max': 5.23046875,                 |\n",
      "|              |              |                     |              |                                                     'min': -24.61441421508789,         |\n",
      "|              |              |                     |              |                                                     'range': 29.84488296508789}}}},    |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                              |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\n",
      "| output       | output       | output              | output       | {'args': {'data_in_0': {'stat': {}}}}                                                  |\n",
      "+--------------+--------------+---------------------+--------------+----------------------------------------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pass_args = {\n",
    "    \"by\": \"type\",                                                            # collect statistics by node name\n",
    "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
    "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
    "    \"weight_statistics\": {\n",
    "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
    "    },\n",
    "    \"activation_statistics\": {\n",
    "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
    "    },\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
    "}\n",
    "\n",
    "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Perform the same quantisation flow to the bigger JSC network that you have trained in lab1. You must be aware that now the `pass_args` for your custom network might be different if you have used more than the `Linear` layer in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../mase_output/Lab_Output_My_Model_50_Epoch/software/training_ckpts/best-v5.ckpt\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    %seq_blocks_4 : [num_users=1] = call_module[target=seq_blocks.4](args = (%seq_blocks_3,), kwargs = {})\n",
      "    %seq_blocks_5 : [num_users=1] = call_module[target=seq_blocks.5](args = (%seq_blocks_4,), kwargs = {})\n",
      "    %seq_blocks_6 : [num_users=1] = call_module[target=seq_blocks.6](args = (%seq_blocks_5,), kwargs = {})\n",
      "    %seq_blocks_7 : [num_users=1] = call_module[target=seq_blocks.7](args = (%seq_blocks_6,), kwargs = {})\n",
      "    %seq_blocks_8 : [num_users=1] = call_module[target=seq_blocks.8](args = (%seq_blocks_7,), kwargs = {})\n",
      "    return seq_blocks_8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    %seq_blocks_4 : [num_users=1] = call_module[target=seq_blocks.4](args = (%seq_blocks_3,), kwargs = {})\n",
      "    %seq_blocks_5 : [num_users=1] = call_module[target=seq_blocks.5](args = (%seq_blocks_4,), kwargs = {})\n",
      "    %seq_blocks_6 : [num_users=1] = call_module[target=seq_blocks.6](args = (%seq_blocks_5,), kwargs = {})\n",
      "    %seq_blocks_7 : [num_users=1] = call_module[target=seq_blocks.7](args = (%seq_blocks_6,), kwargs = {})\n",
      "    %seq_blocks_8 : [num_users=1] = call_module[target=seq_blocks.8](args = (%seq_blocks_7,), kwargs = {})\n",
      "    return seq_blocks_8\n",
      "Network overview:\n",
      "{'placeholder': 1, 'get_attr': 0, 'call_function': 0, 'call_method': 0, 'call_module': 9, 'output': 1}\n",
      "Layer types:\n",
      "[BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Linear(in_features=16, out_features=40, bias=True), BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Linear(in_features=40, out_features=25, bias=True), BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Linear(in_features=25, out_features=5, bias=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling weight statistics: 100%|██████████| 11/11 [00:00<00:00, 8794.77it/s]\n",
      "Profiling act statistics: 100%|██████████| 4/4 [00:00<00:00, 65.39it/s]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| Node name    | Fx Node op   | Mase type           | Mase op      | Software Param                                                                           |\n",
      "+==============+==============+=====================+==============+==========================================================================================+\n",
      "| x            | placeholder  | placeholder         | placeholder  | {'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                          |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                  |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                       |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 512,                        |\n",
      "|              |              |                     |              |                                                     'max': 1.9807130098342896,           |\n",
      "|              |              |                     |              |                                                     'min': -1.2019455432891846,          |\n",
      "|              |              |                     |              |                                                     'range': 3.1826586723327637}}}},     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 40,                            |\n",
      "|              |              |                     |              |                                                  'mean': 0.009731101803481579,           |\n",
      "|              |              |                     |              |                                                  'variance': 0.021054942160844803}}},    |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 640,                         |\n",
      "|              |              |                     |              |                                                    'mean': -0.012746375985443592,        |\n",
      "|              |              |                     |              |                                                    'variance': 0.022547153756022453}}}}, |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_3 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                          |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                  |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                       |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_4 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 1280,                       |\n",
      "|              |              |                     |              |                                                     'max': 1.7223162651062012,           |\n",
      "|              |              |                     |              |                                                     'min': -1.9408807754516602,          |\n",
      "|              |              |                     |              |                                                     'range': 3.6631970405578613}}}},     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_5 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 25,                            |\n",
      "|              |              |                     |              |                                                  'mean': -0.006091854069381952,          |\n",
      "|              |              |                     |              |                                                  'variance': 0.010305427946150303}}},    |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 1000,                        |\n",
      "|              |              |                     |              |                                                    'mean': -0.004322155378758907,        |\n",
      "|              |              |                     |              |                                                    'variance': 0.008761032484471798}}}}, |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_6 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                          |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                  |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                       |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_7 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 800,                        |\n",
      "|              |              |                     |              |                                                     'max': 2.3660888671875,              |\n",
      "|              |              |                     |              |                                                     'min': -1.930548071861267,           |\n",
      "|              |              |                     |              |                                                     'range': 4.296637058258057}}}},      |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_8 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 5,                             |\n",
      "|              |              |                     |              |                                                  'mean': -0.09602034837007523,           |\n",
      "|              |              |                     |              |                                                  'variance': 0.011149059981107712}}},    |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 125,                         |\n",
      "|              |              |                     |              |                                                    'mean': -0.03193478286266327,         |\n",
      "|              |              |                     |              |                                                    'variance': 0.05434480309486389}}}},  |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| output       | output       | output              | output       | {'args': {'data_in_0': {'stat': {}}}}                                                    |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n",
      "    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n",
      "    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n",
      "    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n",
      "    %seq_blocks_4 : [num_users=1] = call_module[target=seq_blocks.4](args = (%seq_blocks_3,), kwargs = {})\n",
      "    %seq_blocks_5 : [num_users=1] = call_module[target=seq_blocks.5](args = (%seq_blocks_4,), kwargs = {})\n",
      "    %seq_blocks_6 : [num_users=1] = call_module[target=seq_blocks.6](args = (%seq_blocks_5,), kwargs = {})\n",
      "    %seq_blocks_7 : [num_users=1] = call_module[target=seq_blocks.7](args = (%seq_blocks_6,), kwargs = {})\n",
      "    %seq_blocks_8 : [num_users=1] = call_module[target=seq_blocks.8](args = (%seq_blocks_7,), kwargs = {})\n",
      "    return seq_blocks_8\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mCompare nodes:\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34m\n",
      "| Ori name     | New name     | MASE_TYPE           | Mase_OP      | Original type   | Quantized type   | Changed   |\n",
      "|--------------+--------------+---------------------+--------------+-----------------+------------------+-----------|\n",
      "| x            | x            | placeholder         | placeholder  | x               | x                | False     |\n",
      "| seq_blocks_0 | seq_blocks_0 | module              | batch_norm1d | BatchNorm1d     | BatchNorm1d      | False     |\n",
      "| seq_blocks_1 | seq_blocks_1 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| seq_blocks_2 | seq_blocks_2 | module_related_func | linear       | Linear          | LinearInteger    | True      |\n",
      "| seq_blocks_3 | seq_blocks_3 | module              | batch_norm1d | BatchNorm1d     | BatchNorm1d      | False     |\n",
      "| seq_blocks_4 | seq_blocks_4 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| seq_blocks_5 | seq_blocks_5 | module_related_func | linear       | Linear          | LinearInteger    | True      |\n",
      "| seq_blocks_6 | seq_blocks_6 | module              | batch_norm1d | BatchNorm1d     | BatchNorm1d      | False     |\n",
      "| seq_blocks_7 | seq_blocks_7 | module_related_func | relu         | ReLU            | ReLU             | False     |\n",
      "| seq_blocks_8 | seq_blocks_8 | module_related_func | linear       | Linear          | LinearInteger    | True      |\n",
      "| output       | output       | output              | output       | output          | output           | False     |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       3 |         0 |           3 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       3 |         0 |           3 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and model specifications\n",
    "batch_size = 8\n",
    "model_name = \"jsc-tiny-x10\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Retrieve model information and initialize the model\n",
    "# Assuming get_model_info and get_model functions are pre-defined\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "# Load the model from a checkpoint file\n",
    "model = load_model(\n",
    "    load_name=\"../mase_output/Lab_Output_My_Model_50_Epoch/software/training_ckpts/best-v5.ckpt\",\n",
    "    load_type=\"pl\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# Initialize the input generator for the model\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# Generate the Mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# report graph is an analysis pass that shows you the detailed information in the graph\n",
    "from chop.passes.graph import report_graph_analysis_pass\n",
    "_ = report_graph_analysis_pass(mg)\n",
    "\n",
    "\n",
    "pass_args = {\n",
    "    \"by\": \"type\",                                                            # collect statistics by node name\n",
    "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
    "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
    "    \"weight_statistics\": {\n",
    "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
    "    },\n",
    "    \"activation_statistics\": {\n",
    "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
    "    },\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
    "}\n",
    "\n",
    "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})\n",
    "\n",
    "pass_args = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "ori_mg = MaseGraph(model=model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "\n",
    "mg, _ = quantize_transform_pass(mg, pass_args)\n",
    "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write code to show and verify that the weights of these layers are indeed quantised. You might need to go through the source code of the implementation of the quantisation pass and also the implementation of the [Quantized Layers](../../machop/chop/passes/transforms/quantize/quantized_modules/linear.py) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference found at name: seq_blocks_2, MASE type: module_related_func, MASE operation: linear\n",
      "Original module: <class 'torch.nn.modules.linear.Linear'>, Old Non Quantized Weights: tensor([[-0.0312,  0.1250, -0.0923, -0.2323, -0.0515,  0.1775, -0.0179,  0.1851,\n",
      "         -0.0339,  0.0698, -0.0141,  0.0019, -0.2413, -0.1191, -0.2104, -0.0343]],\n",
      "       grad_fn=<SliceBackward0>) --> New module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.linear.LinearInteger'>, New Quantized Weights: tensor([[-0.0000,  0.1250, -0.0625, -0.2500, -0.0625,  0.1875, -0.0000,  0.1875,\n",
      "         -0.0625,  0.0625, -0.0000,  0.0000, -0.2500, -0.1250, -0.1875, -0.0625]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Difference found at name: seq_blocks_5, MASE type: module_related_func, MASE operation: linear\n",
      "Original module: <class 'torch.nn.modules.linear.Linear'>, Old Non Quantized Weights: tensor([[ 0.0497, -0.0559,  0.0175, -0.0045,  0.0795,  0.1399, -0.1013, -0.0333,\n",
      "          0.0246,  0.0914, -0.0778, -0.1215,  0.0155,  0.1367, -0.0362, -0.2130,\n",
      "          0.1124, -0.1671, -0.0646, -0.0880,  0.0124,  0.0092, -0.0666,  0.0286,\n",
      "         -0.1770, -0.0771, -0.0248,  0.1295, -0.0093, -0.0011, -0.1092, -0.0055,\n",
      "         -0.0741, -0.0980,  0.1860, -0.0968, -0.0452,  0.0878,  0.0946,  0.1057]],\n",
      "       grad_fn=<SliceBackward0>) --> New module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.linear.LinearInteger'>, New Quantized Weights: tensor([[ 0.0625, -0.0625,  0.0000, -0.0000,  0.0625,  0.1250, -0.1250, -0.0625,\n",
      "          0.0000,  0.0625, -0.0625, -0.1250,  0.0000,  0.1250, -0.0625, -0.1875,\n",
      "          0.1250, -0.1875, -0.0625, -0.0625,  0.0000,  0.0000, -0.0625,  0.0000,\n",
      "         -0.1875, -0.0625, -0.0000,  0.1250, -0.0000, -0.0000, -0.1250, -0.0000,\n",
      "         -0.0625, -0.1250,  0.1875, -0.1250, -0.0625,  0.0625,  0.1250,  0.1250]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Difference found at name: seq_blocks_8, MASE type: module_related_func, MASE operation: linear\n",
      "Original module: <class 'torch.nn.modules.linear.Linear'>, Old Non Quantized Weights: tensor([[-0.3195, -0.0037, -0.2968,  0.0584,  0.1211,  0.2713,  0.1203, -0.0250,\n",
      "         -0.1020, -0.0727, -0.0265,  0.2700, -0.2691,  0.3053, -0.2221,  0.3354,\n",
      "         -0.1450, -0.0420, -0.2243, -0.2594, -0.0766,  0.3295, -0.1473,  0.1601,\n",
      "         -0.2462]], grad_fn=<SliceBackward0>) --> New module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.linear.LinearInteger'>, New Quantized Weights: tensor([[-0.3125, -0.0000, -0.3125,  0.0625,  0.1250,  0.2500,  0.1250, -0.0000,\n",
      "         -0.1250, -0.0625, -0.0000,  0.2500, -0.2500,  0.3125, -0.2500,  0.3125,\n",
      "         -0.1250, -0.0625, -0.2500, -0.2500, -0.0625,  0.3125, -0.1250,  0.1875,\n",
      "         -0.2500]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "from chop.passes.graph.utils import get_mase_op, get_mase_type, get_node_actual_target\n",
    "import torch\n",
    "\n",
    "# Iterate over pairs of nodes from the original and modified graphs\n",
    "for ori_n, n in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
    "    # Check if the node's target module has changed type after modification\n",
    "    if type(get_node_actual_target(n)) != type(get_node_actual_target(ori_n)):\n",
    "        \n",
    "        # Retrieve the original and quantized modules from the nodes\n",
    "        ori_module = get_node_actual_target(ori_n)\n",
    "        quant_module = get_node_actual_target(n)\n",
    "        \n",
    "        # Print the difference information and print the first weights of each module\n",
    "        print(f'Difference found at name: {n.name}, '\n",
    "              f'MASE type: {get_mase_type(n)}, MASE operation: {get_mase_op(n)}\\n'\n",
    "              f'Original module: {type(ori_module)}, Old Non Quantized Weights: {ori_module.weight[0:1]} --> '\n",
    "              f'New module: {type(quant_module)}, New Quantized Weights: {quant_module.get_quantized_weight()[0:1]}')\n",
    "        \n",
    "        # ### NOTE: Can print complete weights by removing the [0:1] from the print statements above ###\n",
    "        # # # Print the weights of the original and quantized modules\n",
    "        # print(f'Weight of original module: {ori_module.weight}')\n",
    "        # print(f'Weights of quantized module: {quant_module.get_quantized_weight()}')\n",
    "        \n",
    "        # ### NOTE: Can compare output of original and quantised module ###\n",
    "        # # # Generate a random input tensor based on the input feature size of the quantized module\n",
    "        # test_input = torch.randn(quant_module.in_features)\n",
    "        # print(f'Random generated test input: {test_input}')\n",
    "        # # Apply the original and quantized modules to the test input and print the outputs\n",
    "        # print(f'Output for original module: {ori_module(test_input)}')\n",
    "        # print(f'Output for quantized module: {quant_module(test_input)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mg_node, ori_mg_node in zip(mg.fx_graph.nodes, ori_mg.fx_graph.nodes):\n",
    "#     print(mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"])\n",
    "#     if mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"] == \"linear\" and ori_mg_node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"] == \"linear\":\n",
    "#         mg_weight = mg_node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"]\n",
    "#         ori_mg_weight = ori_mg_node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"]\n",
    "#         print(f\"mg Node: {mg_node.name}, Weight: {mg_weight} \\n ori_mg Node: {ori_mg_node.name}, Weight: {ori_mg_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The command line interface\n",
    "\n",
    "The same flow can also be executed on the command line throw the `transform` action.\n",
    "\n",
    "```bash\n",
    "# make sure you have the same printout\n",
    "pwd\n",
    "# it should show\n",
    "# your_dir/mase-tools/machop\n",
    "\n",
    "# enter the following command\n",
    "./ch transform --config configs/examples/jsc_toy_by_type.toml --task cls --cpu=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Load your own pre-trained JSC network, and perform perform the quantisation using the command line interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[Optional] Write your own pass\n",
    "\n",
    "Many examples of existing passes are in the [source code](../..//machop/chop/passes/__init__.py), the [test files](../../machop/test/passes) for these passes also contain useful information on helping you to understand how these passes are used.\n",
    "\n",
    "Implement a pass to count the number of FLOPs (floating-point operations) and BitOPs (bit-wise operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the parent directory and then into 'machop'\n",
    "os.chdir('../machop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17920\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.analysis.quantization import calculate_flops_pass, calculate_flops_mg_pass\n",
    "\n",
    "data = calculate_flops_mg_pass(ori_mg)\n",
    "\n",
    "print(data[1]['total_flops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch.nn as nn\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "from chop.passes.graph.analysis.quantization import calculate_flops_pass\n",
    "# from torchprofile import profile_macs\n",
    "\n",
    "# class JSC_Tiny(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(JSC_Tiny, self).__init__()\n",
    "#         self.seq_blocks = nn.Sequential(\n",
    "#             # 1st LogicNets Layer\n",
    "#             nn.BatchNorm1d(16),  # input_quant       # 0\n",
    "#             nn.ReLU(16),  # 1\n",
    "#             nn.Linear(16, 5),  # linear              # 2\n",
    "#             # nn.BatchNorm1d(5),  # output_quant       # 3\n",
    "#             nn.ReLU(5),  # 4\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.seq_blocks(x)\n",
    "\n",
    "\n",
    "# # Define batch size and model specifications\n",
    "# batch_size = 16\n",
    "\n",
    "# # Creating an input tensor of the shape (1, 16, 16)\n",
    "# x = torch.rand(8, 16, 16).cuda()\n",
    "# simple_model = JSC_Tiny().cuda()\n",
    "\n",
    "# macs = profile_macs(simple_model, (x,))\n",
    "# print(macs)\n",
    "\n",
    "\n",
    "# print(calculate_flops('2', '2', '2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
